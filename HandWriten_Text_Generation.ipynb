{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SIIPdvpkrGLO"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt',\n",
        "        'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(filepath, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "\n",
        "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
        "\n",
        "\n",
        "text = text[300000:800000]\n",
        "\n",
        "\n",
        "characters = sorted(set(text))\n",
        "\n",
        "\n",
        "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDZwPjF9sKcl",
        "outputId": "74cedbce-7fc1-4f5a-9cbe-26829ab24f2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "\n",
        "\n",
        "sentences = []\n",
        "next_char = []\n"
      ],
      "metadata": {
        "id": "bw6v2woMsKZQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text[i: i + SEQ_LENGTH])\n",
        "    next_char.append(text[i + SEQ_LENGTH])\n",
        "\n",
        "\n",
        "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
        "              len(characters)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences),\n",
        "              len(characters)), dtype=np.bool)\n",
        "\n",
        "\n",
        "for i, satz in enumerate(sentences):\n",
        "    for t, char in enumerate(satz):\n",
        "        x[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_char[i]]] = 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh7LZIDqsKWm",
        "outputId": "502fee0a-51a8-4eb6-dca5-b9d9d2c20ed8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-4feb3c307947>:7: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  len(characters)), dtype=np.bool)\n",
            "<ipython-input-5-4feb3c307947>:9: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  len(characters)), dtype=np.bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Activation, Dense, LSTM\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128,\n",
        "               input_shape=(SEQ_LENGTH,\n",
        "                            len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.01))\n",
        "\n",
        "\n",
        "model.fit(x, y, batch_size=256, epochs=4)\n",
        "\n",
        "\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzIGNbTDsKT-",
        "outputId": "f1a059c1-82cc-4196-985f-4093af6121a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "651/651 [==============================] - 126s 190ms/step - loss: 2.6975\n",
            "Epoch 2/4\n",
            "651/651 [==============================] - 117s 180ms/step - loss: 2.3058\n",
            "Epoch 3/4\n",
            "651/651 [==============================] - 116s 179ms/step - loss: 2.1929\n",
            "Epoch 4/4\n",
            "651/651 [==============================] - 112s 173ms/step - loss: 2.1124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(length, temperature):\n",
        "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_predictions[0, t, char_to_index[char]] = 1\n",
        "\n",
        "\n",
        "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
        "        next_index = sample(predictions,\n",
        "                                 temperature)\n",
        "        next_character = index_to_char[next_index]\n",
        "\n",
        "\n",
        "        generated += next_character\n",
        "        sentence = sentence[1:] + next_character\n",
        "    return generated\n"
      ],
      "metadata": {
        "id": "l6_h3kAQsKSC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j87G6RIVtaK1",
        "outputId": "7a8c1db9-6f20-4835-af3b-42bf03d67790"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ry: though\n",
            "i have for the most part been the the the the the the stard the mand the to the the the the mand the sould the beat the sored with the fore so the hand the the the the to mand the the the the the the the the har sourd the the the the the soust the dore the the the the cand the the care the the the the the here the pares the sor\n"
          ]
        }
      ]
    }
  ]
}